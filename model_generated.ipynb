{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of being granted a loan: 0.7900563392864988\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "class RawFeats:\n",
    "    def __init__(self, feats):\n",
    "        self.feats = feats\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.feats]\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Define the raw features to be selected\n",
    "selected_feats = ['Married', 'Education', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term','Gender', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())  # Use MinMaxScaler to ensure non-negative values\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the feature selector\n",
    "feature_selector = SelectKBest(score_func=chi2)  # Select features based on chi-square test\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('raw_feats', RawFeats(feats=selected_feats)),  # Add the RawFeats step with selected feats\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Take a sample row from the dataset\n",
    "sample_row = X.sample(n=1, random_state=42)\n",
    "\n",
    "# Predict the probability of being granted a loan for the sample row\n",
    "probability = pipeline.predict_proba(sample_row)[0][1]\n",
    "\n",
    "print(\"Probability of being granted a loan:\", probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'feature_selector__k': 2, 'pca__n_components': 2}\n",
      "Best Score: 0.6872947553004941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "18 fits failed out of a total of 27.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 512, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 526, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=2 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 512, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 526, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=3 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 512, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 526, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=4 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 512, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 526, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=3 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 512, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 526, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=4 must be between 0 and min(n_samples, n_features)=2 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 462, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 512, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 526, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=4 must be between 0 and min(n_samples, n_features)=3 with svd_solver='full'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Tombra\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.68729476        nan        nan\n",
      " 0.68729476 0.68239279        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "class RawFeats:\n",
    "    def __init__(self, feats):\n",
    "        self.feats = feats\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.feats]\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Define the raw features to be selected\n",
    "selected_feats = ['Married', 'Education', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term','Gender', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())  # Use MinMaxScaler to ensure non-negative values\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the feature selector\n",
    "feature_selector = SelectKBest(score_func=chi2)  # Select features based on chi-square test\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('raw_feats', RawFeats(feats=selected_feats)),  # Add the RawFeats step with selected feats\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'feature_selector__k': [1, 2, 3],\n",
    "    'pca__n_components': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
