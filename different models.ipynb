{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.6905537459283387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y, y_pred)\n",
    "print(f'Train set accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Save the model to a file\n",
    "filename = 'loan_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>600.00000</td>\n",
       "      <td>564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5403.459283</td>\n",
       "      <td>1621.245798</td>\n",
       "      <td>146.412162</td>\n",
       "      <td>342.00000</td>\n",
       "      <td>0.842199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6109.041673</td>\n",
       "      <td>2926.248369</td>\n",
       "      <td>85.587325</td>\n",
       "      <td>65.12041</td>\n",
       "      <td>0.364878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2877.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3812.500000</td>\n",
       "      <td>1188.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5795.000000</td>\n",
       "      <td>2297.250000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>360.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81000.000000</td>\n",
       "      <td>41667.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>480.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "count       614.000000         614.000000  592.000000         600.00000   \n",
       "mean       5403.459283        1621.245798  146.412162         342.00000   \n",
       "std        6109.041673        2926.248369   85.587325          65.12041   \n",
       "min         150.000000           0.000000    9.000000          12.00000   \n",
       "25%        2877.500000           0.000000  100.000000         360.00000   \n",
       "50%        3812.500000        1188.500000  128.000000         360.00000   \n",
       "75%        5795.000000        2297.250000  168.000000         360.00000   \n",
       "max       81000.000000       41667.000000  700.000000         480.00000   \n",
       "\n",
       "       Credit_History  \n",
       "count      564.000000  \n",
       "mean         0.842199  \n",
       "std          0.364878  \n",
       "min          0.000000  \n",
       "25%          1.000000  \n",
       "50%          1.000000  \n",
       "75%          1.000000  \n",
       "max          1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())  # Use MinMaxScaler to ensure non-negative values\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the feature selector\n",
    "feature_selector = SelectKBest(score_func=chi2, k=5)  # Select top 5 features based on chi-square test\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y, y_pred)\n",
    "\n",
    "\n",
    "# Save the model to a file\n",
    "filename = 'loan_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.6889250814332247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'pca__n_components': [2, 3, 4],\n",
    "    'model__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search on the entire dataset\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the training set using the best model\n",
    "y_pred = best_model.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y, y_pred)\n",
    "print(f'Train set accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6910569105691057\n",
      "Best parameters found by grid search:\n",
      "{'C': 0.1, 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Convert numerical columns to numeric data type\n",
    "X[numerical_columns] = X[numerical_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Initialize grid search with logistic regression model\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "\n",
    "# Train the model using grid search\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('numerical',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   MinMaxScaler())]),\n",
      "                                                  ['ApplicantIncome',\n",
      "                                                   'CoapplicantIncome',\n",
      "                                                   'LoanAmount',\n",
      "                                                   'Loan_Amount_Term']),\n",
      "                                                 ('categorical',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('encoder',\n",
      "                                                                   OneHotEncoder(drop='first'))]),\n",
      "                                                  ['Gender', 'Married',\n",
      "                                                   'Education', 'Self_Employed',\n",
      "                                                   'Property_Area'])])),\n",
      "                ('feature_selector',\n",
      "                 Pipeline(steps=[('selector',\n",
      "                                  SelectKBest(k=3,\n",
      "                                              score_func=<function chi2 at 0x0000022D74384550>)),\n",
      "                                 ('pca', PCA(n_components=2))])),\n",
      "                ('model', RandomForestRegressor(max_depth=5))])\n",
      "Best Score: 0.017499947709115338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset and define the target variable\n",
    "df = pd.read_csv(r'C:\\Users\\Tombra\\deployment\\deployment\\data.csv')\n",
    "X = df.drop(columns=['Loan_Status', 'Loan_ID'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())  # Use MinMaxScaler to ensure non-negative values\n",
    "])\n",
    "categorical_preprocessor = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_preprocessor, numerical_columns),\n",
    "        ('categorical', categorical_preprocessor, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Create the feature selector\n",
    "feature_selector = Pipeline(steps=[\n",
    "    ('selector', SelectKBest(score_func=chi2)),\n",
    "    ('pca', PCA())\n",
    "])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selector', feature_selector),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'feature_selector__selector__k': [3, 5],  # Vary the number of selected features for SelectKBest\n",
    "    'feature_selector__pca__n_components': [1, 2, 3],  # Vary the number of components for PCA based on available features\n",
    "    'model__n_estimators': [100, 200, 300],  # Vary the number of estimators\n",
    "    'model__max_depth': [None, 5, 10],  # Vary the maximum depth\n",
    "}\n",
    "\n",
    "# Create the grid search object within the pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit the grid search on the entire dataset\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model and its performance\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best model and its score\n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
